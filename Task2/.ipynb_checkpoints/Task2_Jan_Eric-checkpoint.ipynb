{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6110c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5656196",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.read_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task2\\task2_k49am2lqi\\train_features.csv')\n",
    "train_label = pd.read_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task2\\task2_k49am2lqi\\train_labels.csv')\n",
    "test_feat = pd.read_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task2\\task2_k49am2lqi\\test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04e8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abgabe = pd.DataFrame({'pid': test_feat.iloc[0::12, 0].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275e2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = train_feat.sort_values(by=['pid','Time'])\n",
    "#test_feat = test_feat.sort_values(by=['pid','Time'])\n",
    "train_label = train_label.sort_values(by=['pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4411ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: neu schreiben!!! straight anwenden\n",
    "#TODO Neu schreiben*********************************************************************************************************************\n",
    "\n",
    "def make_features(data):\n",
    "    a = []\n",
    "    calc_feat =  [np.nanmean, np.nanvar] # [np.nansum,  np.nanmean, np.nanvar,np.nanmedian, np.nanmax, np.nanmin]\n",
    "    \n",
    "    for i in range(int(data.shape[0] / 12)):\n",
    "        data_without = data[i*12 : (i+1) * 12, 2:] #everything after Age \n",
    "        features = np.empty((6, data[:, 2:].shape[1]))\n",
    "        \n",
    "        for i, feat in enumerate(calc_feat):\n",
    "            features[i] = feat(data_without, axis=0)\n",
    "        a.append(features)\n",
    "    return np.asarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0e292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\AppData\\Local\\Temp/ipykernel_5708/148306006.py:13: RuntimeWarning: Mean of empty slice\n",
      "  features[i] = feat(data_without, axis=0)\n",
      "C:\\Users\\erics\\AppData\\Local\\Temp/ipykernel_5708/148306006.py:13: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  features[i] = feat(data_without, axis=0)\n"
     ]
    }
   ],
   "source": [
    "train_feat_new = make_features(train_feat.to_numpy())\n",
    "test_feat_new = make_features(test_feat.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c53715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18995, 210)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_new = np.resize(train_feat_new, ((18995, 210)))\n",
    "train_feat_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d4c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 210)\n"
     ]
    }
   ],
   "source": [
    "test_feat_new = np.resize(test_feat_new, ((12664, 210)))\n",
    "print(test_feat_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d9ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_label\n",
    "labels.pop(\"pid\")\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f034257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.impute import SimpleImputer\n",
    "#imputer2 = SimpleImputer(strategy='median')\n",
    "#train_feat_new2MEDIAN = imputer2.fit_transform(train_feat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ee8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_feat_newMEDIAN = imputer2.fit_transform(test_feat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232fdf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:372: RuntimeWarning: invalid value encountered in add\n",
      "  distances += XX\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:474: RuntimeWarning: overflow encountered in multiply\n",
      "  XX = X * X\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:475: RuntimeWarning: overflow encountered in multiply\n",
      "  YY = Y * Y\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:476: RuntimeWarning: invalid value encountered in subtract\n",
      "  distances -= np.dot(XX, missing_Y.T)\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:477: RuntimeWarning: invalid value encountered in subtract\n",
      "  distances -= np.dot(missing_X, YY.T)\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:475: RuntimeWarning: overflow encountered in multiply\n",
      "  YY = Y * Y\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:477: RuntimeWarning: invalid value encountered in subtract\n",
      "  distances -= np.dot(missing_X, YY.T)\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:475: RuntimeWarning: overflow encountered in multiply\n",
      "  YY = Y * Y\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:477: RuntimeWarning: invalid value encountered in subtract\n",
      "  distances -= np.dot(missing_X, YY.T)\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=3, weights='distance')\n",
    "train_feat_new2MEDIAN = imputer.fit_transform(train_feat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d948db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\utils\\extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:372: RuntimeWarning: invalid value encountered in add\n",
      "  distances += XX\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:474: RuntimeWarning: overflow encountered in multiply\n",
      "  XX = X * X\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:475: RuntimeWarning: overflow encountered in multiply\n",
      "  YY = Y * Y\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:476: RuntimeWarning: invalid value encountered in subtract\n",
      "  distances -= np.dot(XX, missing_Y.T)\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:477: RuntimeWarning: invalid value encountered in subtract\n",
      "  distances -= np.dot(missing_X, YY.T)\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:475: RuntimeWarning: overflow encountered in multiply\n",
      "  YY = Y * Y\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=3, weights='distance')\n",
    "test_feat_newMEDIAN = imputer.fit_transform(test_feat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f216211",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_imputed_JAN_ERIC_distance\", train_feat_new2MEDIAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8998bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_imputed_JAN_ERIC_distance\", test_feat_newMEDIAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b64c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_new2MEDIAN = np.float32(train_feat_new2MEDIAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44455af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_new2MEDIAN = np.nan_to_num(train_feat_new2MEDIAN, nan=0.0, posinf=None, neginf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c30cde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True in np.isnan(train_feat_new2MEDIAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63b9c3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_new2MEDIAN.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb9bcd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True in np.isinf(train_feat_new2MEDIAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc23708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_newMEDIAN = np.float32(test_feat_newMEDIAN)\n",
    "test_feat_newMEDIAN = np.nan_to_num(test_feat_newMEDIAN, nan=0.0, posinf=None, neginf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee20e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edcec9c9",
   "metadata": {},
   "source": [
    "Subtask 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aee27947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier', RandomForestClassifier(max_depth=3))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier(max_depth=3))])\n",
    "\n",
    "y = labels[2000:, 0]\n",
    "X = train_feat_new2MEDIAN[2000:]\n",
    "\n",
    "pipe.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dca54c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:993: RuntimeWarning: overflow encountered in subtract\n",
      "  X -= self.mean_\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5708/3604238905.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_feat_new2MEDIAN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mRocCurveDisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, **predict_proba_params)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_proba_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_final_estimator_has\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"decision_function\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict_proba(train_feat_new2MEDIAN[:2000])[:,1]\n",
    "RocCurveDisplay.from_predictions(labels[:2000, 0], y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5511933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "y = labels[:,:10]\n",
    "model = MultiOutputClassifier(pipe).fit(train_feat_new2MEDIAN, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5f9a683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8833654 , 0.79087555, 0.72214603, 0.72497791, 0.71500113,\n",
       "       0.77805589, 0.88108426, 0.80422757, 0.75952205, 0.89025601])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = model.predict_proba(train_feat_new2MEDIAN)\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred = y_pred[:,:,1]\n",
    "y_pred = np.transpose(y_pred)\n",
    "roc_auc_score(y, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8683c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test_feat_newMEDIAN)\n",
    "y_pred = np.asarray(y_pred)\n",
    "y_pred = y_pred[:,:,1]\n",
    "y_pred = np.transpose(y_pred)\n",
    "\n",
    "i = 0\n",
    "#TODO Neu schreiben*********************************************************************************************************************\n",
    "for name in ['LABEL_BaseExcess','LABEL_Fibrinogen','LABEL_AST','LABEL_Alkalinephos','LABEL_Bilirubin_total','LABEL_Lactate','LABEL_TroponinI','LABEL_SaO2','LABEL_Bilirubin_direct','LABEL_EtCO2']:\n",
    "    Abgabe[name] = y_pred[:,i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2f829c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.687805</td>\n",
       "      <td>0.318280</td>\n",
       "      <td>0.524469</td>\n",
       "      <td>0.515496</td>\n",
       "      <td>0.548625</td>\n",
       "      <td>0.437125</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.478157</td>\n",
       "      <td>0.118534</td>\n",
       "      <td>0.270972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.231506</td>\n",
       "      <td>0.079095</td>\n",
       "      <td>0.236839</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.227024</td>\n",
       "      <td>0.139856</td>\n",
       "      <td>0.257358</td>\n",
       "      <td>0.149608</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>0.213308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.363535</td>\n",
       "      <td>0.080958</td>\n",
       "      <td>0.223436</td>\n",
       "      <td>0.209416</td>\n",
       "      <td>0.219718</td>\n",
       "      <td>0.330211</td>\n",
       "      <td>0.252053</td>\n",
       "      <td>0.394973</td>\n",
       "      <td>0.031106</td>\n",
       "      <td>0.304034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.243527</td>\n",
       "      <td>0.266459</td>\n",
       "      <td>0.269292</td>\n",
       "      <td>0.144862</td>\n",
       "      <td>0.242821</td>\n",
       "      <td>0.155796</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.232609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.268636</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.227558</td>\n",
       "      <td>0.230155</td>\n",
       "      <td>0.235986</td>\n",
       "      <td>0.172443</td>\n",
       "      <td>0.240407</td>\n",
       "      <td>0.172443</td>\n",
       "      <td>0.034967</td>\n",
       "      <td>0.195278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>9989</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.079210</td>\n",
       "      <td>0.239320</td>\n",
       "      <td>0.224343</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.242707</td>\n",
       "      <td>0.155667</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.184959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>9991</td>\n",
       "      <td>0.468270</td>\n",
       "      <td>0.157623</td>\n",
       "      <td>0.255545</td>\n",
       "      <td>0.223422</td>\n",
       "      <td>0.232805</td>\n",
       "      <td>0.330517</td>\n",
       "      <td>0.204062</td>\n",
       "      <td>0.383307</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.287036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>9992</td>\n",
       "      <td>0.453260</td>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.209376</td>\n",
       "      <td>0.204776</td>\n",
       "      <td>0.206315</td>\n",
       "      <td>0.220475</td>\n",
       "      <td>0.204955</td>\n",
       "      <td>0.399602</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.231635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>9994</td>\n",
       "      <td>0.619040</td>\n",
       "      <td>0.227772</td>\n",
       "      <td>0.383777</td>\n",
       "      <td>0.399617</td>\n",
       "      <td>0.407132</td>\n",
       "      <td>0.535384</td>\n",
       "      <td>0.169620</td>\n",
       "      <td>0.554246</td>\n",
       "      <td>0.096520</td>\n",
       "      <td>0.258544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.493174</td>\n",
       "      <td>0.077592</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.212576</td>\n",
       "      <td>0.217651</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.210947</td>\n",
       "      <td>0.331536</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>0.233933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0          0.687805          0.318280   0.524469   \n",
       "1      10001          0.231506          0.079095   0.236839   \n",
       "2      10003          0.363535          0.080958   0.223436   \n",
       "3      10004          0.237828          0.081894   0.243527   \n",
       "4      10005          0.268636          0.094527   0.227558   \n",
       "...      ...               ...               ...        ...   \n",
       "12659   9989          0.240573          0.079210   0.239320   \n",
       "12660   9991          0.468270          0.157623   0.255545   \n",
       "12661   9992          0.453260          0.088798   0.209376   \n",
       "12662   9994          0.619040          0.227772   0.383777   \n",
       "12663   9997          0.493174          0.077592   0.217747   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.515496               0.548625       0.437125   \n",
       "1                0.227232               0.227024       0.139856   \n",
       "2                0.209416               0.219718       0.330211   \n",
       "3                0.266459               0.269292       0.144862   \n",
       "4                0.230155               0.235986       0.172443   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.224343               0.223173       0.139749   \n",
       "12660            0.223422               0.232805       0.330517   \n",
       "12661            0.204776               0.206315       0.220475   \n",
       "12662            0.399617               0.407132       0.535384   \n",
       "12663            0.212576               0.217651       0.291016   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \n",
       "0             0.204836    0.478157                0.118534     0.270972  \n",
       "1             0.257358    0.149608                0.031097     0.213308  \n",
       "2             0.252053    0.394973                0.031106     0.304034  \n",
       "3             0.242821    0.155796                0.033697     0.232609  \n",
       "4             0.240407    0.172443                0.034967     0.195278  \n",
       "...                ...         ...                     ...          ...  \n",
       "12659         0.242707    0.155667                0.030029     0.184959  \n",
       "12660         0.204062    0.383307                0.036061     0.287036  \n",
       "12661         0.204955    0.399602                0.033326     0.231635  \n",
       "12662         0.169620    0.554246                0.096520     0.258544  \n",
       "12663         0.210947    0.331536                0.030965     0.233933  \n",
       "\n",
       "[12664 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd38033",
   "metadata": {},
   "source": [
    "Subtask 2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4064a660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(class_weight='balanced', max_depth=3))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier(max_depth=3, class_weight='balanced'))])\n",
    "\n",
    "y = labels[2000:, 10]\n",
    "X = train_feat_new2MEDIAN[2000:]\n",
    "\n",
    "pipe.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e93eef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pipe.predict_proba(train_feat_new2MEDIAN[:2000])[:,1]\n",
    "RocCurveDisplay.from_predictions(labels[:2000, 10], y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34a033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict_proba(test_feat_newMEDIAN)[:,1]\n",
    "\n",
    "i = 0\n",
    "for name in ['LABEL_Sepsis']:\n",
    "    Abgabe[name] = y_pred\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da9e6159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.687805</td>\n",
       "      <td>0.318280</td>\n",
       "      <td>0.524469</td>\n",
       "      <td>0.515496</td>\n",
       "      <td>0.548625</td>\n",
       "      <td>0.437125</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.478157</td>\n",
       "      <td>0.118534</td>\n",
       "      <td>0.270972</td>\n",
       "      <td>0.577528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.231506</td>\n",
       "      <td>0.079095</td>\n",
       "      <td>0.236839</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.227024</td>\n",
       "      <td>0.139856</td>\n",
       "      <td>0.257358</td>\n",
       "      <td>0.149608</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>0.213308</td>\n",
       "      <td>0.422182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.363535</td>\n",
       "      <td>0.080958</td>\n",
       "      <td>0.223436</td>\n",
       "      <td>0.209416</td>\n",
       "      <td>0.219718</td>\n",
       "      <td>0.330211</td>\n",
       "      <td>0.252053</td>\n",
       "      <td>0.394973</td>\n",
       "      <td>0.031106</td>\n",
       "      <td>0.304034</td>\n",
       "      <td>0.515058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.243527</td>\n",
       "      <td>0.266459</td>\n",
       "      <td>0.269292</td>\n",
       "      <td>0.144862</td>\n",
       "      <td>0.242821</td>\n",
       "      <td>0.155796</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.444790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.268636</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.227558</td>\n",
       "      <td>0.230155</td>\n",
       "      <td>0.235986</td>\n",
       "      <td>0.172443</td>\n",
       "      <td>0.240407</td>\n",
       "      <td>0.172443</td>\n",
       "      <td>0.034967</td>\n",
       "      <td>0.195278</td>\n",
       "      <td>0.442168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>9989</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.079210</td>\n",
       "      <td>0.239320</td>\n",
       "      <td>0.224343</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.242707</td>\n",
       "      <td>0.155667</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.184959</td>\n",
       "      <td>0.439919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>9991</td>\n",
       "      <td>0.468270</td>\n",
       "      <td>0.157623</td>\n",
       "      <td>0.255545</td>\n",
       "      <td>0.223422</td>\n",
       "      <td>0.232805</td>\n",
       "      <td>0.330517</td>\n",
       "      <td>0.204062</td>\n",
       "      <td>0.383307</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.287036</td>\n",
       "      <td>0.570043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>9992</td>\n",
       "      <td>0.453260</td>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.209376</td>\n",
       "      <td>0.204776</td>\n",
       "      <td>0.206315</td>\n",
       "      <td>0.220475</td>\n",
       "      <td>0.204955</td>\n",
       "      <td>0.399602</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.231635</td>\n",
       "      <td>0.481149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>9994</td>\n",
       "      <td>0.619040</td>\n",
       "      <td>0.227772</td>\n",
       "      <td>0.383777</td>\n",
       "      <td>0.399617</td>\n",
       "      <td>0.407132</td>\n",
       "      <td>0.535384</td>\n",
       "      <td>0.169620</td>\n",
       "      <td>0.554246</td>\n",
       "      <td>0.096520</td>\n",
       "      <td>0.258544</td>\n",
       "      <td>0.653616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.493174</td>\n",
       "      <td>0.077592</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.212576</td>\n",
       "      <td>0.217651</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.210947</td>\n",
       "      <td>0.331536</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>0.233933</td>\n",
       "      <td>0.502283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0          0.687805          0.318280   0.524469   \n",
       "1      10001          0.231506          0.079095   0.236839   \n",
       "2      10003          0.363535          0.080958   0.223436   \n",
       "3      10004          0.237828          0.081894   0.243527   \n",
       "4      10005          0.268636          0.094527   0.227558   \n",
       "...      ...               ...               ...        ...   \n",
       "12659   9989          0.240573          0.079210   0.239320   \n",
       "12660   9991          0.468270          0.157623   0.255545   \n",
       "12661   9992          0.453260          0.088798   0.209376   \n",
       "12662   9994          0.619040          0.227772   0.383777   \n",
       "12663   9997          0.493174          0.077592   0.217747   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.515496               0.548625       0.437125   \n",
       "1                0.227232               0.227024       0.139856   \n",
       "2                0.209416               0.219718       0.330211   \n",
       "3                0.266459               0.269292       0.144862   \n",
       "4                0.230155               0.235986       0.172443   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.224343               0.223173       0.139749   \n",
       "12660            0.223422               0.232805       0.330517   \n",
       "12661            0.204776               0.206315       0.220475   \n",
       "12662            0.399617               0.407132       0.535384   \n",
       "12663            0.212576               0.217651       0.291016   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0             0.204836    0.478157                0.118534     0.270972   \n",
       "1             0.257358    0.149608                0.031097     0.213308   \n",
       "2             0.252053    0.394973                0.031106     0.304034   \n",
       "3             0.242821    0.155796                0.033697     0.232609   \n",
       "4             0.240407    0.172443                0.034967     0.195278   \n",
       "...                ...         ...                     ...          ...   \n",
       "12659         0.242707    0.155667                0.030029     0.184959   \n",
       "12660         0.204062    0.383307                0.036061     0.287036   \n",
       "12661         0.204955    0.399602                0.033326     0.231635   \n",
       "12662         0.169620    0.554246                0.096520     0.258544   \n",
       "12663         0.210947    0.331536                0.030965     0.233933   \n",
       "\n",
       "       LABEL_Sepsis  \n",
       "0          0.577528  \n",
       "1          0.422182  \n",
       "2          0.515058  \n",
       "3          0.444790  \n",
       "4          0.442168  \n",
       "...             ...  \n",
       "12659      0.439919  \n",
       "12660      0.570043  \n",
       "12661      0.481149  \n",
       "12662      0.653616  \n",
       "12663      0.502283  \n",
       "\n",
       "[12664 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66c822",
   "metadata": {},
   "source": [
    "Subtask 3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fea4381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "#Indeces 11, 12, 13, 14\n",
    "y = labels[2000:, 11]\n",
    "X = train_feat_new2MEDIAN[2000:]\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "regr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dc6d827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39210751952953693"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regr.predict(train_feat_new2MEDIAN[:2000])\n",
    "loss = r2_score(labels[:2000, 11], y_pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39f15658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "#Indeces 11, 12, 13, 14\n",
    "y = labels[:,11:]\n",
    "X = train_feat_new2MEDIAN[:]\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "model = MultiOutputRegressor(regr).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "787d0908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39612445, 0.56457971, 0.35661703, 0.60444647])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(train_feat_new2MEDIAN[:2000])\n",
    "loss = r2_score(labels[:2000, 11:], y_pred, multioutput='raw_values')\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b54ca438",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_feat_newMEDIAN)\n",
    "\n",
    "i = 0\n",
    "for name in ['LABEL_RRate','LABEL_ABPm','LABEL_SpO2','LABEL_Heartrate']:\n",
    "    Abgabe[name] = y_pred[:,i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a7c690b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.687805</td>\n",
       "      <td>0.318280</td>\n",
       "      <td>0.524469</td>\n",
       "      <td>0.515496</td>\n",
       "      <td>0.548625</td>\n",
       "      <td>0.437125</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.478157</td>\n",
       "      <td>0.118534</td>\n",
       "      <td>0.270972</td>\n",
       "      <td>0.577528</td>\n",
       "      <td>15.414150</td>\n",
       "      <td>82.965146</td>\n",
       "      <td>98.523316</td>\n",
       "      <td>83.437676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.231506</td>\n",
       "      <td>0.079095</td>\n",
       "      <td>0.236839</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.227024</td>\n",
       "      <td>0.139856</td>\n",
       "      <td>0.257358</td>\n",
       "      <td>0.149608</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>0.213308</td>\n",
       "      <td>0.422182</td>\n",
       "      <td>18.038728</td>\n",
       "      <td>88.444578</td>\n",
       "      <td>95.366078</td>\n",
       "      <td>100.701171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.363535</td>\n",
       "      <td>0.080958</td>\n",
       "      <td>0.223436</td>\n",
       "      <td>0.209416</td>\n",
       "      <td>0.219718</td>\n",
       "      <td>0.330211</td>\n",
       "      <td>0.252053</td>\n",
       "      <td>0.394973</td>\n",
       "      <td>0.031106</td>\n",
       "      <td>0.304034</td>\n",
       "      <td>0.515058</td>\n",
       "      <td>18.096691</td>\n",
       "      <td>82.965146</td>\n",
       "      <td>98.039600</td>\n",
       "      <td>88.547777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.243527</td>\n",
       "      <td>0.266459</td>\n",
       "      <td>0.269292</td>\n",
       "      <td>0.144862</td>\n",
       "      <td>0.242821</td>\n",
       "      <td>0.155796</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.444790</td>\n",
       "      <td>16.784511</td>\n",
       "      <td>73.406817</td>\n",
       "      <td>95.964119</td>\n",
       "      <td>87.419994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.268636</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.227558</td>\n",
       "      <td>0.230155</td>\n",
       "      <td>0.235986</td>\n",
       "      <td>0.172443</td>\n",
       "      <td>0.240407</td>\n",
       "      <td>0.172443</td>\n",
       "      <td>0.034967</td>\n",
       "      <td>0.195278</td>\n",
       "      <td>0.442168</td>\n",
       "      <td>19.222381</td>\n",
       "      <td>74.189418</td>\n",
       "      <td>95.964119</td>\n",
       "      <td>63.056140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>9989</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.079210</td>\n",
       "      <td>0.239320</td>\n",
       "      <td>0.224343</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.139749</td>\n",
       "      <td>0.242707</td>\n",
       "      <td>0.155667</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.184959</td>\n",
       "      <td>0.439919</td>\n",
       "      <td>19.962176</td>\n",
       "      <td>78.585229</td>\n",
       "      <td>95.943396</td>\n",
       "      <td>100.701171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>9991</td>\n",
       "      <td>0.468270</td>\n",
       "      <td>0.157623</td>\n",
       "      <td>0.255545</td>\n",
       "      <td>0.223422</td>\n",
       "      <td>0.232805</td>\n",
       "      <td>0.330517</td>\n",
       "      <td>0.204062</td>\n",
       "      <td>0.383307</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.287036</td>\n",
       "      <td>0.570043</td>\n",
       "      <td>18.936108</td>\n",
       "      <td>94.052680</td>\n",
       "      <td>98.523316</td>\n",
       "      <td>71.774080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>9992</td>\n",
       "      <td>0.453260</td>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.209376</td>\n",
       "      <td>0.204776</td>\n",
       "      <td>0.206315</td>\n",
       "      <td>0.220475</td>\n",
       "      <td>0.204955</td>\n",
       "      <td>0.399602</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.231635</td>\n",
       "      <td>0.481149</td>\n",
       "      <td>18.156609</td>\n",
       "      <td>68.112892</td>\n",
       "      <td>97.168874</td>\n",
       "      <td>82.799609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>9994</td>\n",
       "      <td>0.619040</td>\n",
       "      <td>0.227772</td>\n",
       "      <td>0.383777</td>\n",
       "      <td>0.399617</td>\n",
       "      <td>0.407132</td>\n",
       "      <td>0.535384</td>\n",
       "      <td>0.169620</td>\n",
       "      <td>0.554246</td>\n",
       "      <td>0.096520</td>\n",
       "      <td>0.258544</td>\n",
       "      <td>0.653616</td>\n",
       "      <td>16.448308</td>\n",
       "      <td>88.444578</td>\n",
       "      <td>98.523316</td>\n",
       "      <td>95.510223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.493174</td>\n",
       "      <td>0.077592</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.212576</td>\n",
       "      <td>0.217651</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>0.210947</td>\n",
       "      <td>0.331536</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>0.233933</td>\n",
       "      <td>0.502283</td>\n",
       "      <td>18.038728</td>\n",
       "      <td>76.637485</td>\n",
       "      <td>98.052568</td>\n",
       "      <td>86.910614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0          0.687805          0.318280   0.524469   \n",
       "1      10001          0.231506          0.079095   0.236839   \n",
       "2      10003          0.363535          0.080958   0.223436   \n",
       "3      10004          0.237828          0.081894   0.243527   \n",
       "4      10005          0.268636          0.094527   0.227558   \n",
       "...      ...               ...               ...        ...   \n",
       "12659   9989          0.240573          0.079210   0.239320   \n",
       "12660   9991          0.468270          0.157623   0.255545   \n",
       "12661   9992          0.453260          0.088798   0.209376   \n",
       "12662   9994          0.619040          0.227772   0.383777   \n",
       "12663   9997          0.493174          0.077592   0.217747   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.515496               0.548625       0.437125   \n",
       "1                0.227232               0.227024       0.139856   \n",
       "2                0.209416               0.219718       0.330211   \n",
       "3                0.266459               0.269292       0.144862   \n",
       "4                0.230155               0.235986       0.172443   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.224343               0.223173       0.139749   \n",
       "12660            0.223422               0.232805       0.330517   \n",
       "12661            0.204776               0.206315       0.220475   \n",
       "12662            0.399617               0.407132       0.535384   \n",
       "12663            0.212576               0.217651       0.291016   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0             0.204836    0.478157                0.118534     0.270972   \n",
       "1             0.257358    0.149608                0.031097     0.213308   \n",
       "2             0.252053    0.394973                0.031106     0.304034   \n",
       "3             0.242821    0.155796                0.033697     0.232609   \n",
       "4             0.240407    0.172443                0.034967     0.195278   \n",
       "...                ...         ...                     ...          ...   \n",
       "12659         0.242707    0.155667                0.030029     0.184959   \n",
       "12660         0.204062    0.383307                0.036061     0.287036   \n",
       "12661         0.204955    0.399602                0.033326     0.231635   \n",
       "12662         0.169620    0.554246                0.096520     0.258544   \n",
       "12663         0.210947    0.331536                0.030965     0.233933   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0          0.577528    15.414150   82.965146   98.523316        83.437676  \n",
       "1          0.422182    18.038728   88.444578   95.366078       100.701171  \n",
       "2          0.515058    18.096691   82.965146   98.039600        88.547777  \n",
       "3          0.444790    16.784511   73.406817   95.964119        87.419994  \n",
       "4          0.442168    19.222381   74.189418   95.964119        63.056140  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "12659      0.439919    19.962176   78.585229   95.943396       100.701171  \n",
       "12660      0.570043    18.936108   94.052680   98.523316        71.774080  \n",
       "12661      0.481149    18.156609   68.112892   97.168874        82.799609  \n",
       "12662      0.653616    16.448308   88.444578   98.523316        95.510223  \n",
       "12663      0.502283    18.038728   76.637485   98.052568        86.910614  \n",
       "\n",
       "[12664 rows x 16 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdab8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# suppose df is a pandas dataframe containing the result\n",
    "Abgabe.to_csv('prediction_Jan_Eric.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a80d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
