{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a2aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "#Code loosly based on https://datascience.stackexchange.com/questions/56804/sckit-learn-cross-validation-and-model-retrain\n",
    "#And our exercise 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f38f7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x1    x2    x3    x4    x5\n",
      "0    0.02  0.05 -0.09 -0.43 -0.08\n",
      "1   -0.13  0.11 -0.08 -0.29 -0.03\n",
      "2    0.08  0.06 -0.07 -0.41 -0.03\n",
      "3    0.02 -0.12  0.01 -0.43 -0.02\n",
      "4   -0.14 -0.12 -0.08 -0.02 -0.08\n",
      "..    ...   ...   ...   ...   ...\n",
      "695  0.31 -0.09  0.04 -0.09  0.03\n",
      "696 -0.26 -0.01  0.02 -0.40  0.05\n",
      "697 -0.27 -0.22 -0.01 -0.32 -0.05\n",
      "698  0.19  0.11 -0.05 -0.27 -0.04\n",
      "699 -0.09 -0.09 -0.06 -0.41 -0.06\n",
      "\n",
      "[700 rows x 5 columns]\n",
      "0     -6.8226793\n",
      "1     -6.3262905\n",
      "2     -9.3027282\n",
      "3     -7.3718925\n",
      "4     -6.0276470\n",
      "         ...    \n",
      "695   -6.1473937\n",
      "696   -6.2148989\n",
      "697   -6.8413411\n",
      "698   -6.5233707\n",
      "699   -5.6766827\n",
      "Name: y, Length: 700, dtype: float64\n",
      "(700, 5)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task1\\task1b_ql4jfi6af0\\train.csv')\n",
    "\n",
    "X = train.iloc[:,2:]\n",
    "Y = train.iloc[:,1]\n",
    "ID = train.iloc[:,0]\n",
    "pd.set_option(\"display.precision\", 7)\n",
    "print(X)\n",
    "print(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf35b8c",
   "metadata": {},
   "source": [
    "Wir verlieren etwas pr√§zision durch das Laden in den DataFrame (durch float precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee6d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X):\n",
    "    l1 = X\n",
    "    l2 = X*X\n",
    "    l3 = np.exp(X)\n",
    "    l4 = np.cos(X)\n",
    "    const = np.ones((X.shape[0],1))\n",
    "    return np.concatenate((l1, l2, l3, l4, const), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8494114",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FunctionTransformer(transform, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42a67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_Test = np.array([[1, 2, 3, 4, 5], [1, 1,1, 1,1], [1, 1,1, 1,1], [1, 1,1, 1,1]])\n",
    "#print(transformer.transform(X_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bdf1b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 21)\n"
     ]
    }
   ],
   "source": [
    "X_trans = transformer.transform(X)\n",
    "print(X_trans.shape)\n",
    "#print(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c5c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha' : np.logspace(-2, 10, num=200)}\n",
    "kf = KFold(n_splits=10)\n",
    "model = Ridge(alpha=1, fit_intercept=False)\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='neg_root_mean_squared_error', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6780b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest RMSE:-1.9517431060906634\n",
      "With alpha: Ridge(alpha=41.504047578504725, fit_intercept=False)\n",
      "And coefficiants. \n",
      "[ 0.0634288  -0.09489264 -0.14181013  0.19592706  0.05507503 -0.05101589\n",
      "  0.016873    0.02516042 -0.0809805   0.0031407  -0.55958855 -0.68431942\n",
      " -0.72761617 -0.43817214 -0.54127371 -0.5717427  -0.60547412 -0.60959287\n",
      " -0.55722284 -0.59850169 -0.5970953 ]\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.fit(X_trans, Y)\n",
    "print(\"Lowest RMSE:\" + str(best_model.best_score_))\n",
    "best_alpha = best_model.best_estimator_\n",
    "print(\"With alpha: \" + str(best_alpha))\n",
    "\n",
    "coefficiants = best_model.best_estimator_.coef_\n",
    "print(\"And coefficiants. \")\n",
    "print(coefficiants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141accc",
   "metadata": {},
   "source": [
    "store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d759aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Coefficiants\n",
      "0      0.0634288\n",
      "1     -0.0948926\n",
      "2     -0.1418101\n",
      "3      0.1959271\n",
      "4      0.0550750\n",
      "5     -0.0510159\n",
      "6      0.0168730\n",
      "7      0.0251604\n",
      "8     -0.0809805\n",
      "9      0.0031407\n",
      "10    -0.5595885\n",
      "11    -0.6843194\n",
      "12    -0.7276162\n",
      "13    -0.4381721\n",
      "14    -0.5412737\n",
      "15    -0.5717427\n",
      "16    -0.6054741\n",
      "17    -0.6095929\n",
      "18    -0.5572228\n",
      "19    -0.5985017\n",
      "20    -0.5970953\n"
     ]
    }
   ],
   "source": [
    "dictionary = {'Coefficiants': coefficiants}\n",
    "avg_acc_df = pd.DataFrame(dictionary )\n",
    "print(avg_acc_df)\n",
    "avg_acc_df.to_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task1\\submission1b.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea71f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06612788 -0.68231224 -0.83384997 -0.05459609 -0.04157483 -0.24778276\n",
      "  0.19426473  0.16548507 -0.03504243  0.10998607 -0.19867299 -0.5892195\n",
      " -0.75919001 -0.08069978  0.00312958  0.12313297 -0.0966012  -0.08219195\n",
      "  0.01657758 -0.05327217  0.        ]\n"
     ]
    }
   ],
   "source": [
    "model2 = Ridge(alpha=5.170920242896756)\n",
    "best_fit = model2.fit(X_trans, Y)\n",
    "coef = best_fit.coef_\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc9f863",
   "metadata": {},
   "source": [
    "Overfitting Data This does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75d8d327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   87.19891672   -67.27010868    28.53822965   158.07550392\n",
      "  -819.69642957   200.04958807  -393.54175642  1953.26216011\n",
      "  -523.63288817  1518.93422167   -86.60565699    65.34027498\n",
      "   -30.9921308   -155.77167729   822.10809668   327.109988\n",
      "  -737.64020339  3890.67031218 -1211.22831197  3799.82175151\n",
      "     0.        ]\n"
     ]
    }
   ],
   "source": [
    "model3 = LinearRegression()\n",
    "best_fit = model3.fit(X_trans, Y)\n",
    "coef = best_fit.coef_\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4719b9a5",
   "metadata": {},
   "source": [
    "Versuche nochmals 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1194da",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "model4 = Ridge(alpha=5.170920242896756, fit_intercept=False)\n",
    "acc_score = []\n",
    "best_acc = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab964214",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index , test_index in kf.split(X):\n",
    "        X_train , X_test = X_trans[train_index,:],X_trans[test_index,:]\n",
    "        Y_train , Y_test = Y[train_index] , Y[test_index]\n",
    "\n",
    "        model4.fit(X_train,Y_train)\n",
    "        pred_values = model4.predict(X_test)\n",
    "\n",
    "        acc = np.sqrt(mean_squared_error(pred_values , Y_test))\n",
    "        if acc < best_acc:\n",
    "            best_acc = acc\n",
    "            best_model = model4\n",
    "            \n",
    "        acc_score.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9278ae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4307405772067234\n",
      "[1.843573765736639, 1.8699164762866314, 2.057294075425951, 2.026010242991757, 1.4307405772067234, 2.204681217568447, 2.091630160510509, 1.9260351914411367, 2.087788569124632, 1.9942842920279915]\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e669f597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16527062 -0.48866734 -0.66385665  0.16679502  0.13286039 -0.29960782\n",
      "  0.09717803  0.13021336 -0.14143101  0.06129912 -0.51987876 -0.97407186\n",
      " -1.13894244 -0.43920514 -0.37836275 -0.38525795 -0.58206931 -0.59837934\n",
      " -0.46457019 -0.562893   -0.53373116]\n"
     ]
    }
   ],
   "source": [
    "print(model4.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c072b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Coefficiants\n",
      "0      0.1652706\n",
      "1     -0.4886673\n",
      "2     -0.6638566\n",
      "3      0.1667950\n",
      "4      0.1328604\n",
      "5     -0.2996078\n",
      "6      0.0971780\n",
      "7      0.1302134\n",
      "8     -0.1414310\n",
      "9      0.0612991\n",
      "10    -0.5198788\n",
      "11    -0.9740719\n",
      "12    -1.1389424\n",
      "13    -0.4392051\n",
      "14    -0.3783627\n",
      "15    -0.3852579\n",
      "16    -0.5820693\n",
      "17    -0.5983793\n",
      "18    -0.4645702\n",
      "19    -0.5628930\n",
      "20    -0.5337312\n"
     ]
    }
   ],
   "source": [
    "dictionary = {'Coefficiants': model4.coef_}\n",
    "avg_acc_df = pd.DataFrame(dictionary )\n",
    "print(avg_acc_df)\n",
    "avg_acc_df.to_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task1\\submission1bV4.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e397c",
   "metadata": {},
   "source": [
    "First using Pandas the data is loaded into a dataframe and then split into X (inputs) and Y (the expected output). Using scikit we can define the ridge regression model and the function KFold that splits our dataset into partitions of the same size. We don't use randomness or shuffeling on the dataset since we have enough datapoints to learn from and that it stays reproducible. \n",
    "Using the FunctionTransformer the input is transformed as mentioned in the task description. \n",
    "We then perform a Gridsearch to find the best alpha parameter for ridge regression. After having found the best alpha we use this alpha to compute the model wheights using ridge regression and a 10-fold cross validation approach. Gridseach also gives us model parameters but since Gridsearch uses rounded values during computation, to speed up computation, we get better wheights doing the learning again as axact as possible. We could take some data out for testing purposes but this is not done here. \n",
    "The model parameters can be read out using .coef_ and then saved to csv via a conversion to pandas.dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13080f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
