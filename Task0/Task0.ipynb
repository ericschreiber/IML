{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bab6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd52133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 12])\n",
      "tensor([[ 0.0000e+00,  7.3802e+02,  1.7641e+03,  4.0016e+02,  9.7874e+02,\n",
      "          2.2409e+03,  1.8676e+03, -9.7728e+02,  9.5009e+02, -1.5136e+02,\n",
      "         -1.0322e+02,  4.1060e+02],\n",
      "        [ 1.0000e+00,  4.0065e+02,  1.4404e+02,  1.4543e+03,  7.6104e+02,\n",
      "          1.2168e+02,  4.4386e+02,  3.3367e+02,  1.4941e+03, -2.0516e+02,\n",
      "          3.1307e+02, -8.5410e+02]])\n",
      "torch.Size([2000, 11])\n",
      "tensor([[10000.0000,  -483.7975,  1288.0571,  -129.8787,  -198.0784,  -334.4876,\n",
      "          -391.4432,  -612.4062,  -676.5240,  1327.2297,  -448.6954],\n",
      "        [10001.0000,  -316.4073,    30.8306,  -313.3567,  -173.2592,  -327.3687,\n",
      "           944.3682,  1122.0174,   112.3387,  1372.3402,  2062.5618]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([10000, 10])\n",
      "tensor([[ 1764.0524,   400.1572,   978.7380,  2240.8933,  1867.5580,  -977.2779,\n",
      "           950.0884,  -151.3572,  -103.2188,   410.5985],\n",
      "        [  144.0436,  1454.2736,   761.0377,   121.6750,   443.8632,   333.6743,\n",
      "          1494.0791,  -205.1583,   313.0677,  -854.0958],\n",
      "        [-2552.9897,   653.6186,   864.4362,  -742.1650,  2269.7546, -1454.3657,\n",
      "            45.7585,  -187.1839,  1532.7792,  1469.3588]])\n"
     ]
    }
   ],
   "source": [
    "#train = np.genfromtxt(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task0\\task0_sl19d1\\train.csv', dtype=None, delimiter=',', names=True)\n",
    "#test = np.genfromtxt(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task0\\task0_sl19d1\\test.csv', dtype=None, delimiter=',', names=True)\n",
    "train = pd.read_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task0\\task0_sl19d1\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task0\\task0_sl19d1\\test.csv')\n",
    "\n",
    "train = torch.Tensor(train.to_numpy(), device=device) \n",
    "test = torch.as_tensor(test.to_numpy(), device=device) \n",
    "print(train.size())\n",
    "print(train[0:2])\n",
    "print(test.size())\n",
    "print(test[0:2])\n",
    "\n",
    "\n",
    "#train = train.view(-1, 1, 1, 10) \n",
    "trainID, trainY, trainX = torch.split(train, (1, 1, 10), dim=1)#items, ID, Y, X1-X10\n",
    "testID, testX = torch.split(test, (1,10), dim = 1)#items, ID, X1-X10\n",
    "print(trainX.size())\n",
    "print(trainX[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c140754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(738.0232)\n",
      "tensor([738.0232])\n",
      "tensor(4.4800e-06)\n"
     ]
    }
   ],
   "source": [
    "#meanX = torch.nn.functional.normalize(trainX, dim=0, p=1.0)\n",
    "meanX = trainX.mean(dim=1)\n",
    "print(meanX[0])\n",
    "print(trainY[0])\n",
    "print((meanX-trainY).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df81fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 1])\n",
      "torch.Size([2000, 1])\n",
      "torch.Size([2000, 2])\n",
      "tensor([10000.0000,   -66.0024], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "testMean = testX.mean(dim=1).view(-1,1)\n",
    "print(testMean.size())\n",
    "print(testID.size())\n",
    "subm = torch.cat((testID, testMean), dim=1)\n",
    "print(subm.size())\n",
    "print(subm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b25d7da",
   "metadata": {},
   "source": [
    "Submission sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b64a37c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Id           y\n",
      "0     10000.0  -66.002423\n",
      "1     10001.0  451.406504\n",
      "2     10002.0 -461.676417\n",
      "3     10003.0   40.501209\n",
      "4     10004.0 -126.744722\n",
      "...       ...         ...\n",
      "1995  11995.0  464.715255\n",
      "1996  11996.0  496.485334\n",
      "1997  11997.0  -35.135409\n",
      "1998  11998.0 -131.679185\n",
      "1999  11999.0  417.269155\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "d = {'Id': testID.view(-1), 'y': testMean.view(-1)}\n",
    "\n",
    "df = pd.DataFrame(data=d, index = None)\n",
    "print(df)\n",
    "df.to_csv(r'C:\\Users\\erics\\Documents\\Programme\\IntroML\\Task0\\submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2dbfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ce94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, the output y is a linear function of (x, x^2, x^3), so\n",
    "# we can consider it as a linear layer neural network. Let's prepare the\n",
    "# tensor (x, x^2, x^3).\n",
    "def polynom(x):\n",
    "    p = torch.tensor([1, 2, 3])\n",
    "    return x.unsqueeze(-1).pow(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49390c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10, 3])\n",
      "torch.Size([10000, 30])\n"
     ]
    }
   ],
   "source": [
    "traindata = polynom(trainX)\n",
    "testdata = polynom(testX)\n",
    "print(traindata.size())\n",
    "\n",
    "traindata = traindata.view(-1,30)\n",
    "testdata = testdata.view(-1,30)\n",
    "print(traindata.size())\n",
    "\n",
    "traindata = torch.nn.functional.normalize(traindata, dim=1, p=2.0)\n",
    "testdata = torch.nn.functional.normalize(testdata, dim=1, p=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e831218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(30, 1)\n",
    "        self.flat = torch.nn.Flatten(0, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.lin1(x)\n",
    "        return self.flat(h)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116dae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "lr = 1e-6\n",
    "batchsize = 4\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6862f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    traindata,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=True,\n",
    "    pin_memory=True, #this instructs DataLoader to use pinned memory and enables faster and asynchronous memory copy from the host to the GPU.\n",
    ")\n",
    "#val_loader = torch.DataLoader(\n",
    "#    val_data,\n",
    "#    batch_size=batch_size,\n",
    "#    shuffle=False,\n",
    "#    pin_memory=True,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6b41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleNet(\n",
      "  (lin1): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (flat): Flatten()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = simpleNet()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a88a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(traindata)\n",
    "print(y_pred.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee413c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2801e+26, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([10000, 1])) that is different to the input size (torch.Size([10000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(y_pred, trainY)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f539219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitSimple(model, traindata):\n",
    "    for i in range(traindata.size()[0]):\n",
    "        data = traindata[i]\n",
    "        #print(data)\n",
    "        data = data[None, :]\n",
    "        y_pred = model(data)\n",
    "        loss = loss_fn(y_pred, trainY[i])\n",
    "        if i % 100 == 99:\n",
    "            print(i, loss.item())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a603a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(traindata)/dataloader.batch_size)):\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            data = data.to(device)\n",
    "            opt.zero_grad()\n",
    "            model(data)\n",
    "            loss = loss_fn(y_pred, trainY[(i-1)*batchsize : i*batchsize])\n",
    "            loss.backward(retain_graph=True)\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e353e0",
   "metadata": {},
   "source": [
    "Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6e8fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2500 [00:00<?, ?it/s]C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([0, 1])) that is different to the input size (torch.Size([10000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([10000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|                                                                                 | 1/2500 [00:00<01:57, 21.36it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [30, 1]], which is output 0 of TBackward, is at version 10002; expected version 10001 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11248/3183870874.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#fitSimple(model, traindata)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11248/719895279.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchsize\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [30, 1]], which is output 0 of TBackward, is at version 10002; expected version 10001 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    fit(model, train_loader)\n",
    "    #fitSimple(model, traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "002bbe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-736.9709, -736.9708, -737.8488, -738.3569, -738.1876, -738.7237,\n",
      "         -738.9340, -738.3490, -737.4790, -737.2138],\n",
      "        [-399.5938, -399.5937, -400.4716, -400.9798, -400.8105, -401.3465,\n",
      "         -401.5569, -400.9718, -400.1019, -399.8367],\n",
      "        [-188.8479, -188.8478, -189.7258, -190.2339, -190.0646, -190.6007,\n",
      "         -190.8110, -190.2260, -189.3560, -189.0908],\n",
      "        [  79.4517,   79.4518,   78.5739,   78.0657,   78.2350,   77.6990,\n",
      "           77.4886,   78.0736,   78.9436,   79.2088],\n",
      "        [ 548.4258,  548.4259,  547.5480,  547.0398,  547.2091,  546.6730,\n",
      "          546.4627,  547.0477,  547.9177,  548.1829],\n",
      "        [ 243.8449,  243.8450,  242.9670,  242.4588,  242.6281,  242.0921,\n",
      "          241.8818,  242.4668,  243.3367,  243.6020],\n",
      "        [ 582.9089,  582.9090,  582.0311,  581.5229,  581.6922,  581.1561,\n",
      "          580.9458,  581.5308,  582.4008,  582.6660],\n",
      "        [ 123.5377,  123.5378,  122.6598,  122.1517,  122.3210,  121.7849,\n",
      "          121.5746,  122.1596,  123.0296,  123.2948],\n",
      "        [-302.1268, -302.1267, -303.0046, -303.5128, -303.3435, -303.8795,\n",
      "         -304.0899, -303.5049, -302.6349, -302.3697],\n",
      "        [-538.1871, -538.1870, -539.0649, -539.5731, -539.4038, -539.9399,\n",
      "         -540.1502, -539.5652, -538.6952, -538.4300]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erics\\anaconda3\\envs\\IML\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([10000, 1])) that is different to the input size (torch.Size([10000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(traindata)\n",
    "loss = loss_fn(y_pred, trainY)\n",
    "print(y_pred[0:10]-trainY[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc3d99",
   "metadata": {},
   "source": [
    "Try random input to get rid of nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3116366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5148, 0.3997, 0.7925, 0.6763, 0.2009, 0.1765, 0.6965, 0.5924, 0.8400,\n",
      "        0.6882, 0.9173, 0.9094, 0.5553, 0.0243, 0.8308, 0.1859, 0.2281, 0.1874,\n",
      "        0.2991, 0.3818, 0.6633, 0.4043, 0.9078, 0.1898, 0.1326, 0.8967, 0.7784,\n",
      "        0.2428, 0.8347, 0.7688])\n",
      "tensor(3.1524, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "randomInput = torch.rand(10, 30, device=device) \n",
    "print(randomInput[0])\n",
    "print(model(randomInput)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe64ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b43175e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17564/1183103135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mRMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "RMSE = mean_squared_error(y, y_pred)**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
